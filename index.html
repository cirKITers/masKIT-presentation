<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>masK'IT by cirKITers</title>

		<link rel="stylesheet" href="reveal.js/dist/reset.css">
		<link rel="stylesheet" href="reveal.js/dist/reveal.css">
		<link rel="stylesheet" href="reveal.js/dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>masK'IT</h1>
					<em>Tackling plateaus in parameterised quantum circuits with even more randomness</em>
					<br/><br/>	
					<p>
						<small>Team: cirKITers</small><br/>
						<small>GitHub: <a href="https://github.com/cirKITers/masKIT">https://github.com/cirKITers/masKIT</a></small>
					</p>
				</section>
				<section>
					<h2>Motivation</h2>
					<ul>
						<li>It is not about the difficulty of climbing plateaus, but leaving them during optimization processes.</li>
					</ul>
					<img src="images/Plateau-Mountain--Y6-Gymnastics-Rivers-and-Mountains-Twinkl-Move-PE-KS2.png"/>
				</section>
				<section>
					<h2>Motivation</h2>
					<ul>
						<li>Barren plateaus (but also local minima) can have a big impact on trainability for parameterized quantum circuits</li>
					</ul>
					<img src="images/no_training.png" height="350">
				</section>
				<section>
					<h2>Idea</h2>
					<ul>
						<li>Dropouts are being used in Machine Learning</li>
						<ul>
							<li>Preventing overfitting</li>
							<li>Helping to train all parts of the Neural Network</li>
						</ul>
					</ul>
					<img src="images/dropout.png" alt="Source: https://towardsdatascience.com/the-less-is-more-of-machine-learning-1f571c0d4481"/>
				</section>
				<section>
					<h2>Questions</h2>
					<p>Do dropouts have a similar effect to quantum circuits as in Machine Learning?</p>
					<p>How do they influence circuits of varying depth and height?</p>
					<p>To which ansätze are dropouts applicable if at all?</p>
				</section>
				<section>
					<h2>Experimental Setup</h2>
					<ul>
						<li>Pennylane to implement hybrid quantum-classical use case</li>
						<li>Gradient Descent implementation for parameter optimization</li>
						<li>Layered circuit ansatz as a template for scaling</li>
					</ul>
					<img src="images/pennylane.png" height="50" />
				</section>
				<section>
					<h2>Circuit Ansatz</h2>
					<ul>
						<li><small>Circuit based on ansatz from McClean, J.R., Boixo, S., Smelyanskiy, V.N. et al. <em>Barren plateaus in quantum neural network training landscapes</em>. Nat Commun 9, 4812 (2018). https://doi.org/10.1038/s41467-018-07090-4</small></li>
						<img src="images/circuit.png"/>
					</ul>
				</section>
				<section>
					<h2>Algorithm</h2>
					<pre data-id="code-animation"><code class="hljs" data-trim>
						if cost does not change for several steps:
							create variations of current circuit
							perform another training step
							measure costs for variations
							pick circuit with lowest cost
						else:
							perform another training step
							measure current cost
					</code></pre>
				</section>
				<section>
					<h2>Ensemble-based Dropout</h2>
					<img src="images/do_graph.png"/>
				</section>
				<section>
					<h2>Results</h2>
					<ul>
						<li>Improved learning rate</li>
						<li>Plot even <em>includes</em> penalty in number of steps for calculated ensembles for dropout</li>
					</ul>
					<img src="images/w10_l10.png" height="350" />
				</section>
				<section>
					<h2>Results</h2>
					<ul>
						<li>Fast learning possible with pretrained parameters when dropped gates are added back into the circuit</li>
					</ul>
					<img src="images/w5_l10.png" width="400"/>
					<img src="images/w5_l10_do.png" width="400"/>
				</section>
				<section>
					<h2>Results</h2>
					<ul>
						<li>Good learning also for higher numbers of layers</li>
						<li>Better understanding needed to improve performance</li>
					</ul>
					<img src="images/w5_l20.png" height="350">
				</section>
				<section>
					<h2>Conclusions so far</h2>
					<ul>
						<li>Rapid learning rates can be achieved</li>
					</ul>
				</section>
				<section>
					<h2>Future Work</h2>
					<ul>
						<li>Exploration of varying sizes of circuits</li>
						<li>Exploration of varying circuit ansätze</li>
						<li>Exploration of varying learning methods</li>
						<li>Exploration of further dropout mechanism</li>
						<li>Devloping better understanding of interdependencies</li>
						<li>Targeted dropout of defined parts of a circuit/layer</li>
					</ul>
				</section>
			</div>
		</div>

		<script src="reveal.js/dist/reveal.js"></script>
		<script src="reveal.js/plugin/notes/notes.js"></script>
		<script src="reveal.js/plugin/markdown/markdown.js"></script>
		<script src="reveal.js/plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
